{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import deeplabcut\n",
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "python_path='F:\\\\Users\\\\Gittis\\\\Dropbox\\\\Python\\\\'\n",
    "sys.path.append(python_path)\n",
    "from gittislab import dataloc\n",
    "task='AllVideoAttempt' # Enter the name of your experiment Task\n",
    "experimenter='BRI' # Enter the name of the experimenter\n",
    "path_config_file=\"C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\config.yaml\"\n",
    "# path_config_file=deeplabcut.create_new_project(task,experimenter,video,copy_videos=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Why not finding:\n",
    "'''\n",
    "/home/brian/Dropbox/Gittis Lab Data/OptoBehavior/Str/Naive/A2A/Ai32/Bilateral/10x10/AG6343_5_BI120220/\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning no paths found with those criteria!\n",
      "F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_3mW_cno\\AG6611_5_BI041621\n",
      "Warning no paths found with those criteria!\n",
      "F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_3mW_cno\\AG6611_6_BI041621\n",
      "Warning no paths found with those criteria!\n",
      "F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_3mW_cno\\AG6846_3_BI041621\n",
      "Warning no paths found with those criteria!\n",
      "F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_3mW_cno\\AG6846_5_BI041621\n",
      "\n",
      "\n",
      "\n",
      "NUMBER OF Unprocessed videos = 4\n"
     ]
    }
   ],
   "source": [
    "#Make a list of video files where Raw*.csv exists but dlc*.h5 does not:\n",
    "conds_inc=[['AG','hm4di','Str','A2A','Ai32',]]\n",
    "ex0=['exclude','Exclude','Other XLS','bad','Bad','Broken',\n",
    "     'pp30','grooming','trig_r_short',] #'trig_r_short','AG6166_8_BI090420'\n",
    "conds_exc=[ex0]\n",
    "basepath='F:\\\\Users\\\\Gittis\\\\Dropbox\\\\Gittis Lab Data\\\\OptoBehavior\\\\'\n",
    "#basepath='F:\\\\Users\\\\Gittis\\\\Dropbox\\\\Gittis Lab Data\\\\OptoBehavior\\\\GPe\\\\Naive\\\\FoxP2\\\\ChR2\\\\Bilateral\\\\10x10_20mW\\\\'\n",
    "#video = dataloc.folders_without_dlc_analysis(basepath,conds_inc,conds_exc)\n",
    "video=[]\n",
    "kp=[]\n",
    "for i,inc in enumerate(conds_inc):\n",
    "    exc=conds_exc[i]\n",
    "    vid_paths=dataloc.video(basepath,inc,exc)\n",
    "    if isinstance(vid_paths,Path):\n",
    "        vid_paths=[vid_paths]\n",
    "    for ii,path in enumerate(vid_paths):    \n",
    "        #Next, let's check if there is also a dlc_analyze file:                \n",
    "        dlc_path=dataloc.gen_paths_recurse(path.parent,inc,exc,'*dlc_analyze.h5')\n",
    "        if isinstance(dlc_path,Path):\n",
    "            dlc_file_exists = True\n",
    "        else:\n",
    "            dlc_file_exists = len(dlc_path) > 0\n",
    "        #print(path)  \n",
    "        if  (dlc_file_exists==False):  #(raw_file_exists == True) and\n",
    "            print(path.parent)\n",
    "            vid= dataloc.video(path.parent)\n",
    "            #print('\\tNO DLC')\n",
    "            video.append(str(vid))\n",
    "            kp.append(path)\n",
    "print('\\n\\n\\nNUMBER OF Unprocessed videos = %d' % len(video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-1000000 for model C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\n",
      "WARNING:tensorflow:From C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\training\\saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\\snapshot-1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\\snapshot-1000000\n",
      "  0%|                                                                                        | 0/25200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_3mW_cno\\AG6611_5_BI041621\\Trial   331.mpg\n",
      "Loading  F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_3mW_cno\\AG6611_5_BI041621\\Trial   331.mpg\n",
      "Duration of video [s]:  840.85 , recorded with  29.97 fps!\n",
      "Overall # of frames:  25200  found with (before cropping) frame dimensions:  1280 512\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25452it [13:25, 31.60it/s]                                                                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  25200\n",
      "Saving results in F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_3mW_cno\\AG6611_5_BI041621...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                        | 0/25206 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_3mW_cno\\AG6611_6_BI041621\\Trial   333.mpg\n",
      "Loading  F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_3mW_cno\\AG6611_6_BI041621\\Trial   333.mpg\n",
      "Duration of video [s]:  841.05 , recorded with  29.97 fps!\n",
      "Overall # of frames:  25206  found with (before cropping) frame dimensions:  1280 512\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25452it [13:24, 31.28it/s]                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  25206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25452it [13:24, 31.63it/s]\n",
      "  0%|                                                                                        | 0/25206 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_3mW_cno\\AG6611_6_BI041621...\n",
      "Starting to analyze %  F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_3mW_cno\\AG6846_3_BI041621\\Trial   327.mpg\n",
      "Loading  F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_3mW_cno\\AG6846_3_BI041621\\Trial   327.mpg\n",
      "Duration of video [s]:  841.05 , recorded with  29.97 fps!\n",
      "Overall # of frames:  25206  found with (before cropping) frame dimensions:  1280 512\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25452it [13:22, 31.35it/s]                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  25206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25452it [13:22, 31.72it/s]\n",
      "  0%|                                                                                        | 0/25205 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_3mW_cno\\AG6846_3_BI041621...\n",
      "Starting to analyze %  F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_3mW_cno\\AG6846_5_BI041621\\Trial   329.mpg\n",
      "Loading  F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_3mW_cno\\AG6846_5_BI041621\\Trial   329.mpg\n",
      "Duration of video [s]:  841.02 , recorded with  29.97 fps!\n",
      "Overall # of frames:  25205  found with (before cropping) frame dimensions:  1280 512\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25452it [13:21, 31.34it/s]                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  25205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25452it [13:22, 31.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_3mW_cno\\AG6846_5_BI041621...\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n",
      "Renaming file to F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_3mW_cno\\AG6611_5_BI041621\\iteration_10_dlc_analyze.h5\n",
      "Renaming file to F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_3mW_cno\\AG6611_6_BI041621\\iteration_10_dlc_analyze.h5\n",
      "Renaming file to F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_3mW_cno\\AG6846_3_BI041621\\iteration_10_dlc_analyze.h5\n",
      "Renaming file to F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_3mW_cno\\AG6846_5_BI041621\\iteration_10_dlc_analyze.h5\n"
     ]
    }
   ],
   "source": [
    "#deeplabcut.evaluate_network(path_config_file, plotting=False)\n",
    "#No longer specify batchsize (?)\n",
    "deeplabcut.analyze_videos(path_config_file,video,videotype='.mpg') #Optimize batchsize or no batch?\n",
    "raw_dlc_fn='*DeepCut_resnetNone_AllVideoAttemptApr20shuffle1_1000000.h5'\n",
    "#raw_dlc_fn='*DLC_resnet50_AllVideoAttemptApr20shuffle1_1000000.h5' #Old\n",
    "pns=dataloc.gen_paths_recurse(basepath,conds_inc[0],ex0,filetype=raw_dlc_fn)\n",
    "if isinstance(pns,Path):\n",
    "    pns=[pns]\n",
    "if len(pns) > 0:\n",
    "    for pn in pns:\n",
    "        newfn = pn.parent.joinpath('iteration_10_dlc_analyze.h5')\n",
    "        print('Renaming file to %s' % newfn)\n",
    "        os.rename(str(pn),str(newfn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renaming file to F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_cno_10hz\\AG6611_5_BI041321\\iteration_10_dlc_analyze.h5\n",
      "Renaming file to F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_cno_10hz\\AG6611_6_BI041321\\iteration_10_dlc_analyze.h5\n",
      "Renaming file to F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_cno_10hz\\AG6845_6_BI041321\\iteration_10_dlc_analyze.h5\n",
      "Renaming file to F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_cno_10hz\\AG6845_9_BI041321\\iteration_10_dlc_analyze.h5\n",
      "Renaming file to F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_cno_10hz\\AG6846_3_BI041321\\iteration_10_dlc_analyze.h5\n",
      "Renaming file to F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\10x10_hm4di_cno_10hz\\AG6846_5_BI041321\\iteration_10_dlc_analyze.h5\n",
      "Renaming file to F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\15min_hm4di_cno_10hz\\AG6611_5_BI041321\\iteration_10_dlc_analyze.h5\n",
      "Renaming file to F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\15min_hm4di_cno_10hz\\AG6611_6_BI041321\\iteration_10_dlc_analyze.h5\n",
      "Renaming file to F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\15min_hm4di_cno_10hz\\AG6611_7_BI040121\\iteration_10_dlc_analyze.h5\n",
      "Renaming file to F:\\Users\\Gittis\\Dropbox\\Gittis Lab Data\\OptoBehavior\\Str\\Naive\\A2A\\Ai32\\Bilateral\\15min_hm4di_cno_10hz\\AG6845_6_BI041321\\iteration_10_dlc_analyze.h5\n"
     ]
    }
   ],
   "source": [
    "#Avoid running on all unless you know what you're doing--> some tracked videos shouldn't be renamed because they shouldn't be used (trig_r with opaque walls)\n",
    "raw_dlc_fn='*DeepCut_resnetNone_AllVideoAttemptApr20shuffle1_1000000.h5'\n",
    "pns=dataloc.gen_paths_recurse(basepath,\n",
    "                              conds_inc[0],ex0, #Define include & exclude criteria\n",
    "                              filetype=raw_dlc_fn)\n",
    "if isinstance(pns,Path):\n",
    "    pns=[pns]\n",
    "if len(pns) > 0:\n",
    "    for pn in pns:\n",
    "        newfn = pn.parent.joinpath('iteration_10_dlc_analyze.h5')\n",
    "        print('Renaming file to %s' % newfn)\n",
    "        os.rename(str(pn),str(newfn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AG', 'hm4di', 'Str', 'A2A', 'Ai32']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conds_inc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If necessary: evaluate a recently run video and determine if the algorithm needs improvement"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
