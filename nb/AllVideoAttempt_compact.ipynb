{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeplabcut\n",
    "path_config_file=\"C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\config.yaml\"\n",
    "video=['F:\\\\Users\\\\Gittis\\\\Dropbox\\\\Gittis Lab Data\\\\OptoBehavior\\\\GPe\\\\Naive\\\\A2A\\\\Ai32\\\\Bilateral\\\\10x10\\\\AG5363_2_BI121719\\\\Trial    38.mpg',\n",
    "       'F:\\\\Users\\\\Gittis\\\\Dropbox\\\\Gittis Lab Data\\\\OptoBehavior\\\\GPe\\\\Naive\\\\A2A\\\\Ai32\\\\Bilateral\\\\10x10\\\\AG5477_4_BI022520\\\\Trial   540.mpg',\n",
    "       'F:\\\\Users\\\\Gittis\\\\Dropbox\\\\Gittis Lab Data\\\\OptoBehavior\\\\GPe\\\\Naive\\\\CAG\\\\Arch\\\\Bilateral\\\\10x10\\\\AG4766_10_BI021120\\\\Trial     2.mpg',\n",
    "       'F:\\\\Users\\\\Gittis\\\\Dropbox\\\\Gittis Lab Data\\\\OptoBehavior\\\\GPe\\\\Naive\\\\CAG\\\\Arch\\\\Bilateral\\\\trig_r\\\\AG4700_5_BI090619\\\\Trial    83.mpg',\n",
    "       'F:\\\\Users\\\\Gittis\\\\Dropbox\\\\Gittis Lab Data\\\\OptoBehavior\\\\Str\\\\Naive\\\\D1\\\\PSAM_PSEM\\\\Bilateral\\\\60min\\\\AG5232_10_BI111519\\\\Trial    25.mpg',\n",
    "       'F:\\\\Users\\\\Gittis\\\\Dropbox\\\\Gittis Lab Data\\\\OptoBehavior\\\\Str\\\\Naive\\\\A2A\\\\ChR2\\\\Left\\\\5x30\\\\AG4700_6_BI083019\\\\Trial   368.mpg',\n",
    "       'F:\\\\Users\\\\Gittis\\\\Dropbox\\\\Gittis Lab Data\\\\OptoBehavior\\\\GPe\\\\Naive\\\\PV\\\\Arch\\\\Bilateral\\\\zone_1\\\\AG4187_2_JS011519\\\\Trial    51.mpg'\n",
    "      ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make a new project\n",
    "task='AllVideoAttempt' # Enter the name of your experiment Task\n",
    "experimenter='BRI' # Enter the name of the experimenter\n",
    "\n",
    "# WARNING: Must run as administrator to have copy_videos = False (allow making symlinks)!!!!!\n",
    "path_config_file=deeplabcut.create_new_project(task,experimenter,video,copy_videos=False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(deeplabcut.create_new_project)\n",
    "print('break test')\n",
    "break\n",
    "print('break test failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Add videos to an existing model / project:\n",
    "new_video=['F:\\\\Users\\\\Gittis\\\\Dropbox\\\\Gittis Lab Data\\\\OptoBehavior\\\\SNr_and_Str\\\\Naive\\\\D1_D1\\\\Ai35_Ai35\\\\Bilateral\\\\10x30\\\\AG5313_4_BI120319\\\\Trial    35.mpg']\n",
    "deeplabcut.add_new_videos(path_config_file,new_video,copy_videos=False)\n",
    "[video.append(new) for new in new_video]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract frames from videos \n",
    "A key point for a successful feature detector is to select diverse frames, which are typical for the behavior you study that should be labeled.\n",
    "\n",
    "This function selects N frames either uniformly sampled from a particular video (or folder) ('uniform'). Note: this might not yield diverse frames, if the behavior is sparsely distributed (consider using kmeans), and/or select frames manually etc.\n",
    "\n",
    "Also make sure to get select data from different (behavioral) sessions and different animals if those vary substantially (to train an invariant feature detector).\n",
    "\n",
    "Individual images should not be too big (i.e. < 850 x 850 pixel). Although this can be taken care of later as well, it is advisable to crop the frames, to remove unnecessary parts of the frame as much as possible.\n",
    "\n",
    "Always check the output of cropping. If you are happy with the results proceed to labeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(deeplabcut.extract_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Automatically extract frames to label manually:\n",
    "%matplotlib inline\n",
    "deeplabcut.extract_frames(path_config_file,algo = 'kmeans') \n",
    "\n",
    "\"\"\" Alternate method:\n",
    "#SELECT RARE EVENTS MANUALLY:\n",
    "%gui wx\n",
    "deeplabcut.extract_frames(path_config_file,'manual')\n",
    "\"\"\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stopped at 83\n",
    "# PST: Add list of points that will be labeled to the .yaml configuration file\n",
    "deeplabcut.label_frames(path_config_file) #Note: this seems to hang upon exit (if not saved first?), or even after successful save\n",
    "#deeplabcut.check_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init=a['scorer']\n",
    "csv_path=r\"C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\labeled-data\\Trial     2\"\n",
    "csv_fn=\"\\\\CollectedData_%s.csv\" % init \n",
    "print(csv_path+csv_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Possibly important: make sure order of columns in \n",
    "import yaml\n",
    "import csv\n",
    "import pandas as pd\n",
    "from os import listdir\n",
    "with open(path_config_file, 'r') as stream:\n",
    "    a=yaml.safe_load(stream)\n",
    "col_order=a['bodyparts']\n",
    "init=a['scorer']\n",
    "base_path=r'C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\labeled-data'\n",
    "dirs=listdir(base_path)\n",
    "for d in dirs:\n",
    "    if 'labeled' not in d:\n",
    "        csv_path=\"%s\\\\%s\" % (base_path,d)\n",
    "        csv_fn=\"\\\\CollectedData_{}.csv\".format(init)\n",
    "        print(\"Analyzing %s\" % csv_path + csv_fn)\n",
    "        df=pd.read_csv(csv_path + csv_fn,header=0)\n",
    "        cols=list(df)\n",
    "        for col in cols:\n",
    "            if 'scorer' not in col:\n",
    "                body_part=df[col][0]\n",
    "                xy=df[col][1]\n",
    "                for ind,part in enumerate(col_order,start=1):\n",
    "                    if body_part == part:                \n",
    "                        new_col_ind=(ind-1)*2+1\n",
    "                        if 'y' in xy:\n",
    "                            new_col_ind +=1\n",
    "                        #print('%s moved to %d' % (body_part+xy,new_col_ind))\n",
    "                        df.insert(new_col_ind,col,df.pop(col))      \n",
    "                        df.to_csv(csv_path + '\\\\CollectedData_BRI.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeplabcut.utils import auxiliaryfunctions\n",
    "from deeplabcut.utils import conversioncode\n",
    "import pdb\n",
    "\n",
    "conversioncode.convertcsv2h5(path_config_file,userfeedback=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdb.pm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.check_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(deeplabcut.create_training_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.create_training_dataset(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(deeplabcut.train_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled-data\\Trial    25\\img091959.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img05849.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img05980.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img06609.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img19360.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img13000.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img033561.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img20130.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img09698.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img044463.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img09065.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img17450.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img047888.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img03353.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img18776.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img23362.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img053550.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img078596.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img09653.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img14474.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img20232.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img05738.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img09954.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img13388.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img05996.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img21269.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img14565.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img24603.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img23354.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img21256.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img04890.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img09462.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img18457.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img16510.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img19575.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img06374.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img23354.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img01316.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    51\\img052393.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img15482.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img110413.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img12517.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img042036.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img07954.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img12881.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img00716.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img00722.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img01045.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img11994.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled-data\\Trial     2\\img18776.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img051840.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img044020.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img01765.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img012365.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img044782.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img060055.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img06641.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img07827.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img059684.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img074638.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img075064.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img21888.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img12081.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img112865.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img24195.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img124720.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img10774.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img14179.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img18561.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img08033.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img19877.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img043981.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img023244.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img24416.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img23905.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img073878.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img043617.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img15035.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img056804.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img080224.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img10604.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img20088.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img08562.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img07492.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img08241.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img003861.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img036279.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img033561.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img083503.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img14808.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img07267.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    51\\img087872.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img12492.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img02494.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img09182.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img17676.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img17839.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img24248.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled-data\\Trial    83\\img028278.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img06281.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img043700.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img07187.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img14495.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img23359.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img05738.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img09666.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img05472.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img13755.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img13006.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img09924.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img078160.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img19714.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    51\\img094670.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img09935.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img105144.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img09646.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    51\\img100210.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img15002.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img21269.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    51\\img044313.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img058722.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img21311.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img023873.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img14536.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img044752.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img000684.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img05948.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img09653.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img13572.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img044706.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img21851.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img013500.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img061363.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img18455.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img044520.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img22367.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    35\\img121939.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img03699.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img054059.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img14702.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    51\\img044111.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img01383.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img085005.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img08257.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img057714.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img053056.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img00934.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled-data\\Trial   540\\img06619.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img01951.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img24172.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img05365.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img19846.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img06470.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img04862.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img081707.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img08332.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img038020.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    51\\img109803.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img01316.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img058299.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img01509.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img21287.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    51\\img113150.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img21615.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img19828.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    51\\img081191.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    35\\img089661.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img19095.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img12465.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img09065.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img19895.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img04720.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img05619.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img029649.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img18550.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img20698.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img11006.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img043720.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img08091.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img20232.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    35\\img059945.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img100877.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    35\\img108018.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    51\\img047584.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img18310.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img110413.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img066402.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img14812.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img023209.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img09632.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img06808.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img06994.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img121356.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img18457.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img12806.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled-data\\Trial   540\\img12363.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img17199.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img01322.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img034810.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    51\\img028993.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img08575.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img12110.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    51\\img036953.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img19694.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img082498.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img19150.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img08479.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    51\\img092401.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img06329.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img16657.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img04603.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img21821.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img07277.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img05849.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   368\\img15432.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img06256.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img07500.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img23979.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img053363.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img078596.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img06838.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img20977.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img072490.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img02144.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img044275.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img16740.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img13305.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    51\\img009581.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    35\\img134829.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img08551.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img23341.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img22710.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img19876.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    51\\img002726.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img19477.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img05451.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    83\\img002243.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img07097.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img16652.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img13480.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial     2\\img09745.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    38\\img15545.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial    25\\img066424.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "iteration: 1000000 loss: 0.0010 lr: 0.001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labeled-data\\Trial    83\\img025424.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n",
      "labeled-data\\Trial   540\\img07954.png C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-31:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1319, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[{{node fifo_queue_enqueue}}]]\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\threading.py\", line 926, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\threading.py\", line 870, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 81, in load_and_enqueue\n",
      "    sess.run(enqueue_op, feed_dict=food)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\client\\session.py\", line 1348, in _do_call\n",
      "    raise type(e)(node_def, op, message)\n",
      "tensorflow.python.framework.errors_impl.CancelledError: Enqueue operation was cancelled\n",
      "\t [[node fifo_queue_enqueue (defined at C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:67) ]]\n",
      "\n",
      "Caused by op 'fifo_queue_enqueue', defined at:\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\runpy.py\", line 193, in _run_module_as_main\n",
      "    \"__main__\", mod_spec)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\runpy.py\", line 85, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\traitlets\\config\\application.py\", line 664, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 583, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 149, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\asyncio\\base_events.py\", line 541, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\asyncio\\base_events.py\", line 1786, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\asyncio\\events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\ioloop.py\", line 690, in <lambda>\n",
      "    lambda f: self._run_callback(functools.partial(callback, future))\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\ioloop.py\", line 743, in _run_callback\n",
      "    ret = callback()\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\gen.py\", line 787, in inner\n",
      "    self.run()\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\gen.py\", line 748, in run\n",
      "    yielded = self.gen.send(value)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 361, in process_one\n",
      "    yield gen.maybe_future(dispatch(*args))\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 268, in dispatch_shell\n",
      "    yield gen.maybe_future(handler(stream, idents, msg))\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 541, in execute_request\n",
      "    user_expressions, allow_stdin,\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tornado\\gen.py\", line 209, in wrapper\n",
      "    yielded = next(result)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 300, in do_execute\n",
      "    res = shell.run_cell(code, store_history=store_history, silent=silent)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 536, in run_cell\n",
      "    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2858, in run_cell\n",
      "    raw_cell, store_history, silent, shell_futures)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2886, in _run_cell\n",
      "    return runner(coro)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 68, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3063, in run_cell_async\n",
      "    interactivity=interactivity, compiler=compiler, result=result)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3254, in run_ast_nodes\n",
      "    if (await self.run_code(code, result,  async_=asy)):\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3331, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-11-463601e153b8>\", line 4, in <module>\n",
      "    deeplabcut.train_network(path_config_file,maxiters=1000000) #Train for 1,000,000 iterations max\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\training.py\", line 132, in train_network\n",
      "    train(str(poseconfigfile),displayiters,saveiters,maxiters,max_to_keep=max_snapshots_to_keep,keepdeconvweights=keepdeconvweights,allow_growth=allow_growth) #pass on path and file name for pose_cfg.yaml!\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 118, in train\n",
      "    batch, enqueue_op, placeholders = setup_preloading(batch_spec)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py\", line 67, in setup_preloading\n",
      "    enqueue_op = q.enqueue(placeholders_list)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\data_flow_ops.py\", line 345, in enqueue\n",
      "    self._queue_ref, vals, name=scope)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\ops\\gen_data_flow_ops.py\", line 4158, in queue_enqueue_v2\n",
      "    timeout_ms=timeout_ms, name=name)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 788, in _apply_op_helper\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 507, in new_func\n",
      "    return func(*args, **kwargs)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3300, in create_op\n",
      "    op_def=op_def)\n",
      "  File \"C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1801, in __init__\n",
      "    self._traceback = tf_stack.extract_stack()\n",
      "\n",
      "CancelledError (see above for traceback): Enqueue operation was cancelled\n",
      "\t [[node fifo_queue_enqueue (defined at C:\\Users\\Brian\\anaconda3\\envs\\DLC-GPU\\lib\\site-packages\\deeplabcut\\pose_estimation_tensorflow\\train.py:67) ]]\n",
      "\n",
      "\n",
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]],\n",
      " 'all_joints_names': ['top_head',\n",
      "                      'top_tail_base',\n",
      "                      'top_body_center',\n",
      "                      'snout',\n",
      "                      'side_head',\n",
      "                      'side_tail_base',\n",
      "                      'side_left_fore',\n",
      "                      'side_right_fore',\n",
      "                      'side_left_hind',\n",
      "                      'side_right_hind'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-10\\\\UnaugmentedDataSet_AllVideoAttemptApr20\\\\AllVideoAttempt_BRI95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Brian\\\\anaconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-10\\\\UnaugmentedDataSet_AllVideoAttemptApr20\\\\Documentation_data-AllVideoAttempt_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 10,\n",
      " 'num_outputs': 1,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\dlc-models\\\\iteration-10\\\\AllVideoAttemptApr20-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The network is now trained and ready to evaluate. Use the function 'evaluate_network' to evaluate the network.\n",
      "C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20/evaluation-results/  already exists!\n",
      "Running  DLC_resnet50_AllVideoAttemptApr20shuffle1_1000000  with # of trainingiterations: 1000000\n",
      "Initializing ResNet\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\\snapshot-1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\\snapshot-1000000\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "602it [00:24, 24.95it/s]\n",
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]],\n",
      " 'all_joints_names': ['top_head',\n",
      "                      'top_tail_base',\n",
      "                      'top_body_center',\n",
      "                      'snout',\n",
      "                      'side_head',\n",
      "                      'side_tail_base',\n",
      "                      'side_left_fore',\n",
      "                      'side_right_fore',\n",
      "                      'side_left_hind',\n",
      "                      'side_right_hind'],\n",
      " 'batch_size': 1,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-10\\\\UnaugmentedDataSet_AllVideoAttemptApr20\\\\AllVideoAttempt_BRI95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Brian\\\\anaconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-10\\\\UnaugmentedDataSet_AllVideoAttemptApr20\\\\Documentation_data-AllVideoAttempt_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 10,\n",
      " 'num_outputs': 1,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\dlc-models\\\\iteration-10\\\\AllVideoAttemptApr20-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done and results stored for snapshot:  snapshot-1000000\n",
      "Results for 1000000  training iterations: 95 1 train error: 2.27 pixels. Test error: 4.38  pixels.\n",
      "With pcutoff of 0.6  train error: 1.96 pixels. Test error: 4.36 pixels\n",
      "Thereby, the errors are given by the average distances between the labels by DLC and the scorer.\n",
      "The network is evaluated and the results are stored in the subdirectory 'evaluation_results'.\n",
      "If it generalizes well, choose the best model for prediction and update the config file with the appropriate index for the 'snapshotindex'.\n",
      "Use the function 'analyze_video' to make predictions on new videos.\n",
      "Otherwise consider retraining the network (see DeepLabCut workflow Fig 2)\n",
      "Using snapshot-1000000 for model C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\n",
      "Initializing ResNet\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\\snapshot-1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\\snapshot-1000000\n",
      "16it [00:00, 153.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n",
      "Starting to analyze %  Trial     2.mpg\n",
      "Video already analyzed! .\\Trial     2DLC_resnet50_AllVideoAttemptApr20shuffle1_1000000.h5\n",
      "Starting to analyze %  Trial    51.mpg\n",
      "Video already analyzed! .\\Trial    51DLC_resnet50_AllVideoAttemptApr20shuffle1_1000000.h5\n",
      "Starting to analyze %  Trial    25.mpg\n",
      "Video already analyzed! .\\Trial    25DLC_resnet50_AllVideoAttemptApr20shuffle1_1000000.h5\n",
      "Starting to analyze %  Trial    38.mpg\n",
      "Video already analyzed! .\\Trial    38DLC_resnet50_AllVideoAttemptApr20shuffle1_1000000.h5\n",
      "Starting to analyze %  Trial   540.mpg\n",
      "Video already analyzed! .\\Trial   540DLC_resnet50_AllVideoAttemptApr20shuffle1_1000000.h5\n",
      "Starting to analyze %  Trial    35.mpg\n",
      "Video already analyzed! .\\Trial    35DLC_resnet50_AllVideoAttemptApr20shuffle1_1000000.h5\n",
      "Starting to analyze %  Trial    83.mpg\n",
      "Video already analyzed! .\\Trial    83DLC_resnet50_AllVideoAttemptApr20shuffle1_1000000.h5\n",
      "Starting to analyze %  Trial   368.mpg\n",
      "Video already analyzed! .\\Trial   368DLC_resnet50_AllVideoAttemptApr20shuffle1_1000000.h5\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n",
      "Analyzing all the videos in the directory\n",
      "Method  jump  found  43  putative outlier frames.\n",
      "Do you want to proceed with extracting  5  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, comparisonbodyparts) or use a different method.\n",
      "Frames from video Trial   368  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  750.4163333333333 , recorded @  29.97002997002997 fps!\n",
      "Overall # of frames:  22490 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 750.42  seconds.\n",
      "Extracting and downsampling... 43  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:00, 162.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [8868, 13686, 8548, 10685, 14114]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15it [00:00, 143.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Trial   368.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  83  putative outlier frames.\n",
      "Do you want to proceed with extracting  5  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, comparisonbodyparts) or use a different method.\n",
      "Frames from video Trial   540  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  840.3728666666667 , recorded @  29.97002997002997 fps!\n",
      "Overall # of frames:  25186 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 840.37  seconds.\n",
      "Extracting and downsampling... 83  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:00, 157.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [2147, 18404, 16656, 1916, 20064]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Trial   540.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  5837  putative outlier frames.\n",
      "Do you want to proceed with extracting  5  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, comparisonbodyparts) or use a different method.\n",
      "Frames from video Trial    35  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  4501.515045625172 , recorded @  29.96968767906535 fps!\n",
      "Overall # of frames:  134909 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 4501.52  seconds.\n",
      "Extracting and downsampling... 5837  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5837it [00:26, 221.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [46041, 133032, 95400, 86742, 101916]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17it [00:00, 165.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Trial    35.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  1059  putative outlier frames.\n",
      "Do you want to proceed with extracting  5  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, comparisonbodyparts) or use a different method.\n",
      "Frames from video Trial    38  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  840.9150212103641 , recorded @  29.972112953485873 fps!\n",
      "Overall # of frames:  25204 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 840.92  seconds.\n",
      "Extracting and downsampling... 1059  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1059it [00:04, 220.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [20749, 18088, 13575, 374, 21253]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Trial    38.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  387  putative outlier frames.\n",
      "Do you want to proceed with extracting  5  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, comparisonbodyparts) or use a different method.\n",
      "Frames from video Trial     2  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  840.9817499313334 , recorded @  29.96973477968805 fps!\n",
      "Overall # of frames:  25204 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 840.98  seconds.\n",
      "Extracting and downsampling... 387  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:02, 177.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [9297, 3810, 21280, 3786, 18716]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Trial     2.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  3860  putative outlier frames.\n",
      "Do you want to proceed with extracting  5  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, comparisonbodyparts) or use a different method.\n",
      "Frames from video Trial    25  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  3600.7001556443984 , recorded @  29.969726812947457 fps!\n",
      "Overall # of frames:  107912 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 3600.7  seconds.\n",
      "Extracting and downsampling... 3860  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3860it [00:17, 220.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [13249, 62673, 42295, 1140, 4727]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Trial    25.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  282  putative outlier frames.\n",
      "Do you want to proceed with extracting  5  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, comparisonbodyparts) or use a different method.\n",
      "Frames from video Trial    51  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  4203.1322666666665 , recorded @  29.97002997002997 fps!\n",
      "Overall # of frames:  125968 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 4203.13  seconds.\n",
      "Extracting and downsampling... 282  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "282it [00:01, 185.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [33122, 94037, 86553, 116471, 439]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Trial    51.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  841  putative outlier frames.\n",
      "Do you want to proceed with extracting  5  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, comparisonbodyparts) or use a different method.\n",
      "Frames from video Trial    83  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  4247.376466666667 , recorded @  29.97002997002997 fps!\n",
      "Overall # of frames:  127294 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 4247.38  seconds.\n",
      "Extracting and downsampling... 841  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "841it [00:04, 189.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [57173, 34991, 32502, 18628, 1194]\n",
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Trial    83.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Analyzing all the videos in the directory\n",
      "Starting %  . ['C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\videos']\n",
      "Labeled video already created.\n",
      "Starting %  . ['C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\videos']\n",
      "Labeled video already created.\n",
      "Starting %  . ['C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\videos']\n",
      "Labeled video already created.\n",
      "Starting %  . ['C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\videos']\n",
      "Labeled video already created.\n",
      "Starting %  . ['C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\videos']\n",
      "Labeled video already created.\n",
      "Starting %  . ['C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\videos']\n",
      "Labeled video already created.\n",
      "Starting %  . ['C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\videos']\n",
      "Labeled video already created.\n",
      "Starting %  . ['C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\videos']\n",
      "Labeled video already created.\n"
     ]
    }
   ],
   "source": [
    "# One full iteration cycle:\n",
    "deeplabcut.create_training_dataset(path_config_file)\n",
    "vid=\"C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\videos\"\n",
    "deeplabcut.train_network(path_config_file,maxiters=1000000) #Train for 1,000,000 iterations max\n",
    "deeplabcut.evaluate_network(path_config_file, plotting=False)\n",
    "deeplabcut.analyze_videos(path_config_file,[vid],videotype='.mpg',batchsize=16) #Optimize batchsize or no batch?\n",
    "deeplabcut.extract_outlier_frames(path_config_file,[vid], videotype='.mpg',outlieralgorithm='jump',automatic=True) #How to not require input dialog?\n",
    "deeplabcut.create_labeled_video(path_config_file,[vid], videotype='.mpg',filtered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Config:\n",
      "{'all_joints': [[0], [1], [2], [3], [4], [5], [6], [7], [8], [9]],\n",
      " 'all_joints_names': ['top_head',\n",
      "                      'top_tail_base',\n",
      "                      'top_body_center',\n",
      "                      'snout',\n",
      "                      'side_head',\n",
      "                      'side_tail_base',\n",
      "                      'side_left_fore',\n",
      "                      'side_right_fore',\n",
      "                      'side_left_hind',\n",
      "                      'side_right_hind'],\n",
      " 'batch_size': 16,\n",
      " 'bottomheight': 400,\n",
      " 'crop': True,\n",
      " 'crop_pad': 0,\n",
      " 'cropratio': 0.4,\n",
      " 'dataset': 'training-datasets\\\\iteration-10\\\\UnaugmentedDataSet_AllVideoAttemptApr20\\\\AllVideoAttempt_BRI95shuffle1.mat',\n",
      " 'dataset_type': 'default',\n",
      " 'deconvolutionstride': 2,\n",
      " 'deterministic': False,\n",
      " 'display_iters': 1000,\n",
      " 'fg_fraction': 0.25,\n",
      " 'global_scale': 0.8,\n",
      " 'init_weights': 'C:\\\\Users\\\\Brian\\\\anaconda3\\\\envs\\\\DLC-GPU\\\\lib\\\\site-packages\\\\deeplabcut\\\\pose_estimation_tensorflow\\\\models\\\\pretrained\\\\resnet_v1_50.ckpt',\n",
      " 'intermediate_supervision': False,\n",
      " 'intermediate_supervision_layer': 12,\n",
      " 'leftwidth': 400,\n",
      " 'location_refinement': True,\n",
      " 'locref_huber_loss': True,\n",
      " 'locref_loss_weight': 0.05,\n",
      " 'locref_stdev': 7.2801,\n",
      " 'log_dir': 'log',\n",
      " 'max_input_size': 1500,\n",
      " 'mean_pixel': [123.68, 116.779, 103.939],\n",
      " 'metadataset': 'training-datasets\\\\iteration-10\\\\UnaugmentedDataSet_AllVideoAttemptApr20\\\\Documentation_data-AllVideoAttempt_95shuffle1.pickle',\n",
      " 'min_input_size': 64,\n",
      " 'minsize': 100,\n",
      " 'mirror': False,\n",
      " 'multi_step': [[0.005, 10000],\n",
      "                [0.02, 430000],\n",
      "                [0.002, 730000],\n",
      "                [0.001, 1030000]],\n",
      " 'net_type': 'resnet_50',\n",
      " 'num_joints': 10,\n",
      " 'num_outputs': 1,\n",
      " 'optimizer': 'sgd',\n",
      " 'output_stride': 16,\n",
      " 'pos_dist_thresh': 17,\n",
      " 'project_path': 'C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20',\n",
      " 'regularize': False,\n",
      " 'rightwidth': 400,\n",
      " 'save_iters': 50000,\n",
      " 'scale_jitter_lo': 0.5,\n",
      " 'scale_jitter_up': 1.25,\n",
      " 'scoremap_dir': 'test',\n",
      " 'shuffle': True,\n",
      " 'snapshot_prefix': 'C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\dlc-models\\\\iteration-10\\\\AllVideoAttemptApr20-trainset95shuffle1\\\\test\\\\snapshot',\n",
      " 'stride': 8.0,\n",
      " 'topheight': 400,\n",
      " 'weigh_negatives': False,\n",
      " 'weigh_only_present_joints': False,\n",
      " 'weigh_part_predictions': False,\n",
      " 'weight_decay': 0.0001}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using snapshot-1000000 for model C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\n",
      "Initializing ResNet\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\\snapshot-1000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from C:\\Users\\Brian\\DeepLabCut\\examples\\AllVideoAttempt-BRI-2020-04-20\\dlc-models\\iteration-10\\AllVideoAttemptApr20-trainset95shuffle1\\train\\snapshot-1000000\n",
      "  0%|                                                                                        | 0/25186 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n",
      "Starting to analyze %  Trial   540.mpg\n",
      "Loading  Trial   540.mpg\n",
      "Duration of video [s]:  840.37 , recorded with  29.97 fps!\n",
      "Overall # of frames:  25186  found with (before cropping) frame dimensions:  704 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25351it [06:49, 61.35it/s]                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  25186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25351it [06:51, 61.56it/s]\n",
      "  0%|                                                                                        | 0/25204 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in ....\n",
      "Starting to analyze %  Trial     2.mpg\n",
      "Loading  Trial     2.mpg\n",
      "Duration of video [s]:  840.98 , recorded with  29.97 fps!\n",
      "Overall # of frames:  25204  found with (before cropping) frame dimensions:  1280 512\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25452it [13:13, 31.60it/s]                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  25204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25452it [13:13, 32.06it/s]\n",
      "  0%|                                                                                       | 0/107912 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in ....\n",
      "Starting to analyze %  Trial    25.mpg\n",
      "Loading  Trial    25.mpg\n",
      "Duration of video [s]:  3600.7 , recorded with  29.97 fps!\n",
      "Overall # of frames:  107912  found with (before cropping) frame dimensions:  1280 512\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "108979it [56:30, 31.97it/s]                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  107912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "108979it [56:31, 32.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in ....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                       | 0/125968 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to analyze %  Trial    51.mpg\n",
      "Loading  Trial    51.mpg\n",
      "Duration of video [s]:  4203.13 , recorded with  29.97 fps!\n",
      "Overall # of frames:  125968  found with (before cropping) frame dimensions:  704 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "127159it [34:25, 61.58it/s]                                                                                            \n",
      "  0%|                                                                                        | 0/22490 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  125968\n",
      "Saving results in ....\n",
      "Starting to analyze %  Trial   368.mpg\n",
      "Loading  Trial   368.mpg\n",
      "Duration of video [s]:  750.42 , recorded with  29.97 fps!\n",
      "Overall # of frames:  22490  found with (before cropping) frame dimensions:  704 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22624it [06:07, 61.10it/s]                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  22490\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22624it [06:09, 61.28it/s]\n",
      "  0%|                                                                                        | 0/25204 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in ....\n",
      "Starting to analyze %  Trial    38.mpg\n",
      "Loading  Trial    38.mpg\n",
      "Duration of video [s]:  840.92 , recorded with  29.97 fps!\n",
      "Overall # of frames:  25204  found with (before cropping) frame dimensions:  1280 512\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25452it [13:17, 31.04it/s]                                                                                             "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  25204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25452it [13:18, 31.88it/s]\n",
      "  0%|                                                                                       | 0/127294 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in ....\n",
      "Starting to analyze %  Trial    83.mpg\n",
      "Loading  Trial    83.mpg\n",
      "Duration of video [s]:  4247.38 , recorded with  29.97 fps!\n",
      "Overall # of frames:  127294  found with (before cropping) frame dimensions:  704 480\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128472it [35:25, 60.03it/s]                                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  127294\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "128472it [35:26, 60.41it/s]\n",
      "  0%|                                                                                       | 0/134909 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in ....\n",
      "Starting to analyze %  Trial    35.mpg\n",
      "Loading  Trial    35.mpg\n",
      "Duration of video [s]:  4501.52 , recorded with  29.97 fps!\n",
      "Overall # of frames:  134909  found with (before cropping) frame dimensions:  1280 512\n",
      "Starting to extract posture\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "136249it [1:11:22, 32.52it/s]                                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected frames:  134909\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "136249it [1:11:22, 31.81it/s]\n",
      "  0%|                                                                                       | 0/127294 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving results in ....\n",
      "The videos are analyzed. Now your research can truly start! \n",
      " You can create labeled videos with 'create_labeled_video'.\n",
      "If the tracking is not satisfactory for some videos, consider expanding the training set. You can use the function 'extract_outlier_frames' to extract any outlier frames!\n",
      "Analyzing all the videos in the directory\n",
      "Starting %  . ['C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\videos']\n",
      "Loading  Trial    83.mpg and data.\n",
      "127294\n",
      "Duration of video [s]:  4247.38 , recorded with  29.97 fps!\n",
      "Overall # of frames:  127294 with cropped frame dimensions:  704 480\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 127294/127294 [04:50<00:00, 437.62it/s]\n",
      "  0%|                                                                             | 42/25186 [00:00<01:00, 412.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\videos']\n",
      "Loading  Trial   540.mpg and data.\n",
      "25186\n",
      "Duration of video [s]:  840.37 , recorded with  29.97 fps!\n",
      "Overall # of frames:  25186 with cropped frame dimensions:  704 480\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 25186/25186 [00:56<00:00, 444.93it/s]\n",
      "  0%|                                                                             | 43/125968 [00:00<04:57, 422.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\videos']\n",
      "Loading  Trial    51.mpg and data.\n",
      "125968\n",
      "Duration of video [s]:  4203.13 , recorded with  29.97 fps!\n",
      "Overall # of frames:  125968 with cropped frame dimensions:  704 480\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 125968/125968 [04:33<00:00, 461.08it/s]\n",
      "  0%|                                                                              | 24/25204 [00:00<01:45, 238.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\videos']\n",
      "Loading  Trial     2.mpg and data.\n",
      "25204\n",
      "Duration of video [s]:  840.98 , recorded with  29.97 fps!\n",
      "Overall # of frames:  25204 with cropped frame dimensions:  1280 512\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 25204/25204 [01:36<00:00, 261.06it/s]\n",
      "  0%|                                                                             | 26/107912 [00:00<07:10, 250.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\videos']\n",
      "Loading  Trial    25.mpg and data.\n",
      "107912\n",
      "Duration of video [s]:  3600.7 , recorded with  29.97 fps!\n",
      "Overall # of frames:  107912 with cropped frame dimensions:  1280 512\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 107912/107912 [06:38<00:00, 270.92it/s]\n",
      "  0%|                                                                             | 43/22490 [00:00<00:52, 429.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\videos']\n",
      "Loading  Trial   368.mpg and data.\n",
      "22490\n",
      "Duration of video [s]:  750.42 , recorded with  29.97 fps!\n",
      "Overall # of frames:  22490 with cropped frame dimensions:  704 480\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 22490/22490 [00:49<00:00, 452.67it/s]\n",
      "  0%|                                                                              | 26/25204 [00:00<01:40, 250.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\videos']\n",
      "Loading  Trial    38.mpg and data.\n",
      "25204\n",
      "Duration of video [s]:  840.92 , recorded with  29.97 fps!\n",
      "Overall # of frames:  25204 with cropped frame dimensions:  1280 512\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 25204/25204 [01:34<00:00, 267.56it/s]\n",
      "  0%|                                                                             | 26/134909 [00:00<08:52, 253.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting %  . ['C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\videos']\n",
      "Loading  Trial    35.mpg and data.\n",
      "134909\n",
      "Duration of video [s]:  4501.52 , recorded with  29.97 fps!\n",
      "Overall # of frames:  134909 with cropped frame dimensions:  1280 512\n",
      "Generating frames and creating video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 134909/134909 [08:30<00:00, 264.13it/s]\n"
     ]
    }
   ],
   "source": [
    "vid=\"C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\videos\"\n",
    "deeplabcut.analyze_videos(path_config_file,[vid],videotype='.mpg',batchsize=16) #Optimize batchsize or no batch?\n",
    "#deeplabcut.extract_outlier_frames(path_config_file,[vid],videotype='.mpg', outlieralgorithm='jump',automatic=True) #How to not require input dialog?\n",
    "deeplabcut.create_labeled_video(path_config_file,[vid],videotype='.mpg',filtered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "help(deeplabcut.analyze_videos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#deeplabcut.evaluate_network(path_config_file, plotting=False)\n",
    "vid=\"C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\videos\"\n",
    "deeplabcut.analyze_videos(path_config_file,[vid],batchsize=16,videotype='.mpg') #Optimize batchsize or no batch?\n",
    "deeplabcut.create_labeled_video(path_config_file,[vid],videotype='.mpg',filtered=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MANAUL frame extraction:\n",
    "deeplabcut.extract_frames(path_config_file,'manual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "16it [00:00, 152.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyzing all the videos in the directory\n",
      "Method  jump  found  83  putative outlier frames.\n",
      "Do you want to proceed with extracting  5  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, comparisonbodyparts) or use a different method.\n",
      "Frames from video Trial   540  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  840.3728666666667 , recorded @  29.97002997002997 fps!\n",
      "Overall # of frames:  25186 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 840.37  seconds.\n",
      "Extracting and downsampling... 83  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "83it [00:00, 151.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [3849, 18435, 20078, 16655, 23359]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Trial   540.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  282  putative outlier frames.\n",
      "Do you want to proceed with extracting  5  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, comparisonbodyparts) or use a different method.\n",
      "Frames from video Trial    51  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  4203.1322666666665 , recorded @  29.97002997002997 fps!\n",
      "Overall # of frames:  125968 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 4203.13  seconds.\n",
      "Extracting and downsampling... 282  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "282it [00:01, 164.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [28993, 80758, 116776, 44111, 58286]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Trial    51.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  841  putative outlier frames.\n",
      "Do you want to proceed with extracting  5  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, comparisonbodyparts) or use a different method.\n",
      "Frames from video Trial    83  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  4247.376466666667 , recorded @  29.97002997002997 fps!\n",
      "Overall # of frames:  127294 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 4247.38  seconds.\n",
      "Extracting and downsampling... 841  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "841it [00:05, 163.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [13500, 3861, 25794, 57714, 7112]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Trial    83.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  5837  putative outlier frames.\n",
      "Do you want to proceed with extracting  5  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, comparisonbodyparts) or use a different method.\n",
      "Frames from video Trial    35  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  4501.515045625172 , recorded @  29.96968767906535 fps!\n",
      "Overall # of frames:  134909 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 4501.52  seconds.\n",
      "Extracting and downsampling... 5837  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5837it [00:26, 217.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [110317, 95361, 89661, 43482, 20609]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14it [00:00, 136.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Trial    35.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  387  putative outlier frames.\n",
      "Do you want to proceed with extracting  5  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, comparisonbodyparts) or use a different method.\n",
      "Frames from video Trial     2  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  840.9817499313334 , recorded @  29.96973477968805 fps!\n",
      "Overall # of frames:  25204 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 840.98  seconds.\n",
      "Extracting and downsampling... 387  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "387it [00:02, 192.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [6367, 18457, 9948, 22610, 7014]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "13it [00:00, 127.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Trial     2.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  1059  putative outlier frames.\n",
      "Do you want to proceed with extracting  5  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, comparisonbodyparts) or use a different method.\n",
      "Frames from video Trial    38  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  840.9150212103641 , recorded @  29.972112953485873 fps!\n",
      "Overall # of frames:  25204 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 840.92  seconds.\n",
      "Extracting and downsampling... 1059  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1059it [00:05, 196.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [8491, 11660, 2344, 1383, 13006]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12it [00:00, 116.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Trial    38.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  43  putative outlier frames.\n",
      "Do you want to proceed with extracting  5  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, comparisonbodyparts) or use a different method.\n",
      "Frames from video Trial   368  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  750.4163333333333 , recorded @  29.97002997002997 fps!\n",
      "Overall # of frames:  22490 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 750.42  seconds.\n",
      "Extracting and downsampling... 43  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "43it [00:00, 135.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [14010, 13034, 10685, 6808, 15856]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Trial   368.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n",
      "Method  jump  found  3860  putative outlier frames.\n",
      "Do you want to proceed with extracting  5  of those?\n",
      "If this list is very large, perhaps consider changing the paramters (start, stop, epsilon, comparisonbodyparts) or use a different method.\n",
      "Frames from video Trial    25  already extracted (more will be added)!\n",
      "Loading video...\n",
      "Duration of video [s]:  3600.7001556443984 , recorded @  29.969726812947457 fps!\n",
      "Overall # of frames:  107912 with (cropped) frame dimensions: \n",
      "Kmeans-quantization based extracting of frames from 0.0  seconds to 3600.7  seconds.\n",
      "Extracting and downsampling... 3860  frames from the video.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3860it [00:17, 216.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kmeans clustering ... (this might take a while)\n",
      "Let's select frames indices: [2619, 27602, 60055, 47904, 85005]\n",
      "New video was added to the project! Use the function 'extract_frames' to select frames for labeling.\n",
      "The outlier frames are extracted. They are stored in the subdirectory labeled-data\\Trial    25.\n",
      "Once you extracted frames for all videos, use 'refine_labels' to manually correct the labels.\n"
     ]
    }
   ],
   "source": [
    "vid=\"C:\\\\Users\\\\Brian\\\\DeepLabCut\\\\examples\\\\AllVideoAttempt-BRI-2020-04-20\\\\videos\"\n",
    "deeplabcut.extract_outlier_frames(path_config_file,[vid],outlieralgorithm='jump',videotype='.mpg',automatic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deeplabcut.extract_outlier_frames?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Windows\n",
      "Checking labels if they are outside the image\n",
      "A training dataset file is already found for this video. The refined machine labels are merged to this data!\n",
      "Closing... The refined labels are stored in a subdirectory under labeled-data. Use the function 'merge_datasets' to augment the training dataset, and then re-train a network using create_training_dataset followed by train_network!\n"
     ]
    }
   ],
   "source": [
    "#Manually refine:\n",
    "deeplabcut.refine_labels(path_config_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data sets and updated refinement iteration to 10.\n",
      "Now you can create a new training set for the expanded annotated images (use create_training_dataset).\n"
     ]
    }
   ],
   "source": [
    "#If above successful:\n",
    "deeplabcut.merge_datasets(path_config_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create labeled video\n",
    "This funtion is for visualiztion purpose and can be used to create a video in .mp4 format with labels predicted by the network. This video is saved in the same directory where the original video resides. \n",
    "\n",
    "THIS HAS MANY FUN OPTIONS! \n",
    "\n",
    "``deeplabcut.create_labeled_video(config, videos, videotype='avi', shuffle=1, trainingsetindex=0, filtered=False, save_frames=False, Frames2plot=None, delete=False, displayedbodyparts='all', codec='mp4v', outputframerate=None, destfolder=None, draw_skeleton=False, trailpoints=0, displaycropped=False)``\n",
    "\n",
    "So please check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video[1] + video[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#When satisfied with quality of labeling, create example video:\n",
    "#videofile_path='F:\\\\Users\\\\Gittis\\\\Dropbox\\\\Gittis Lab Data\\\\OptoBehavior\\\\Str\\\\Naive\\\\D1\\\\PSAM_PSEM\\\\Bilateral\\\\60min\\\\AG5232_10_BI111519\\\\Trial    25.mpg'\n",
    "\n",
    "#deeplabcut.filterpredictions(path_config_file,[video[2]],filtertype='median',windowlength=9)\n",
    "deeplabcut.create_labeled_video(path_config_file,video,filtered=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(deeplabcut.create_labeled_video)\n",
    "help(deeplabcut.filterpredictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DLC-GPU] *",
   "language": "python",
   "name": "conda-env-DLC-GPU-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
